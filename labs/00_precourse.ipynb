{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00 Precourse\n",
    "\n",
    "- Paulo Czarnewski  \n",
    "- Spatial Omics Data Analysis 2022\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this tutorial, we will download all datasets necessary for the course and test whether we can load and use the main functions.\n",
    "\n",
    "***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading required libraries\n",
    "\n",
    "First, we can start by loading some libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-11T16:05:16.977541Z",
     "iopub.status.busy": "2022-01-11T16:05:16.976788Z",
     "iopub.status.idle": "2022-01-11T16:05:21.124856Z",
     "shell.execute_reply": "2022-01-11T16:05:21.125360Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import scanpy as sc\n",
    "import anndata as an\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scanorama\n",
    "import tarfile\n",
    "\n",
    "from urllib import request\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also setup some warning and plotting default configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-11T16:05:21.130692Z",
     "iopub.status.busy": "2022-01-11T16:05:21.129924Z",
     "iopub.status.idle": "2022-01-11T16:05:21.131742Z",
     "shell.execute_reply": "2022-01-11T16:05:21.132198Z"
    }
   },
   "outputs": [],
   "source": [
    "#sc.logging.print_versions() # gives errror!!\n",
    "sc.set_figure_params(facecolor=\"white\", figsize=(8, 8))\n",
    "sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory for downloading data\n",
    "for i in ['results','data']:\n",
    "    for j in ['single_cell','spatial_transcriptomics','in_situ_sequencing']:\n",
    "        os.makedirs( '../'+i+'/'+j , exist_ok= True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-11T16:05:21.136673Z",
     "iopub.status.busy": "2022-01-11T16:05:21.136009Z",
     "iopub.status.idle": "2022-01-11T16:05:23.983754Z",
     "shell.execute_reply": "2022-01-11T16:05:23.984337Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define base URL path to the data\n",
    "base_path = 'https://export.uppmax.uu.se/snic2022-23-113/courses/spatial_omics_2022/single_cell/'\n",
    "\n",
    "# Download each dataset\n",
    "for i in ['10X151w1','10X180w1','10x289w3','10x303w3']:\n",
    "    tmp = 'Sountoulidis2022_'+i+'_counts.h5'\n",
    "    request.urlretrieve( base_path+tmp , '../data/single_cell/'+tmp )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check whether the files were downloaded correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/single_cell\n",
      "├── Sountoulidis2022_10X151w1_counts.h5\n",
      "├── Sountoulidis2022_10X180w1_counts.h5\n",
      "├── Sountoulidis2022_10x289w3_counts.h5\n",
      "└── Sountoulidis2022_10x303w3_counts.h5\n",
      "\n",
      "0 directories, 4 files\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "tree ../data/single_cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now read all tables into a list and then merge them into a single AnnData object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "reading ../data/single_cell/Sountoulidis2022_10X151w1_counts.h5\n",
      " (0:00:00)\n",
      "1\n",
      "reading ../data/single_cell/Sountoulidis2022_10X180w1_counts.h5\n",
      " (0:00:01)\n",
      "2\n",
      "reading ../data/single_cell/Sountoulidis2022_10x289w3_counts.h5\n",
      " (0:00:01)\n",
      "3\n",
      "reading ../data/single_cell/Sountoulidis2022_10x303w3_counts.h5\n",
      " (0:00:00)\n"
     ]
    }
   ],
   "source": [
    "# Define paths and get sample_ids\n",
    "obj_list = list()\n",
    "file_list = os.listdir('../data/single_cell')\n",
    "sample_ids = [j.replace('_counts.h5','') for j in [x.replace('Sountoulidis2022_','') for x in file_list]]\n",
    "\n",
    "# Read each table and append to our list\n",
    "for i in range(0,len(file_list)):\n",
    "    print(i)\n",
    "    tmp = sc.read_10x_h5('../data/single_cell/'+file_list[i])\n",
    "    tmp.var_names_make_unique()\n",
    "    tmp.obs['sample_id'] = sample_ids[i]\n",
    "    obj_list.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 25601 × 33538\n",
       "    obs: 'sample_id'\n",
       "    var: 'gene_ids', 'feature_types', 'genome'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge all samples into a single AnnData Object \n",
    "adata = an.concat( obj_list , merge='same' )\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can now save the annData object to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('../results/single_cell', exist_ok=True)\n",
    "adata.write_h5ad('../results/single_cell/scRNAseq.h5ad' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the dataset saved, we can now safelly remove some of these objects from memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove other objects from memory\n",
    "del(obj_list,file_list,sample_ids,adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Transcriptomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-11T16:05:23.994209Z",
     "iopub.status.busy": "2022-01-11T16:05:23.993382Z",
     "iopub.status.idle": "2022-01-11T16:05:24.008242Z",
     "shell.execute_reply": "2022-01-11T16:05:24.009145Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define base URL path to the data\n",
    "base_path = 'https://export.uppmax.uu.se/snic2022-23-113/courses/spatial_omics_2022/spatial_transcriptomics/'    \n",
    "\n",
    "# For each dataset do:\n",
    "for j in ['154441','154442']:\n",
    "    \n",
    "    # Create directory for the dataset\n",
    "    os.makedirs( '../data/spatial_transcriptomics/'+j+'/spatial' , exist_ok= True )\n",
    "    ss='/spatial/'\n",
    "    \n",
    "    # Download necessary files in their respective folder\n",
    "    for i in [j+'/filtered_feature_bc_matrix.h5',\n",
    "              j+ss+'tissue_lowres_image.png',\n",
    "              j+ss+'tissue_hires_image.png',\n",
    "              j+ss+'tissue_positions_list.txt',\n",
    "              j+ss+'scalefactors_json.json']:\n",
    "        request.urlretrieve( base_path+i , '../data/spatial_transcriptomics/'+i.replace('.txt','.csv')  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check whether the files were downloaded correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/spatial_transcriptomics\n",
      "├── 154441\n",
      "│   ├── filtered_feature_bc_matrix.h5\n",
      "│   └── spatial\n",
      "│       ├── scalefactors_json.json\n",
      "│       ├── tissue_hires_image.png\n",
      "│       ├── tissue_lowres_image.png\n",
      "│       └── tissue_positions_list.csv\n",
      "└── 154442\n",
      "    ├── filtered_feature_bc_matrix.h5\n",
      "    └── spatial\n",
      "        ├── scalefactors_json.json\n",
      "        ├── tissue_hires_image.png\n",
      "        ├── tissue_lowres_image.png\n",
      "        └── tissue_positions_list.csv\n",
      "\n",
      "4 directories, 10 files\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "tree ../data/spatial_transcriptomics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now read all tables into a list and then merge them into a single AnnData object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['154441', '154442']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define paths and get sample_ids\n",
    "obj_list = list()\n",
    "file_list = os.listdir('../data/spatial_transcriptomics')\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "reading ../data/spatial_transcriptomics/154441/filtered_feature_bc_matrix.h5\n",
      " (0:00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chrav452/miniconda3/envs/spatial2022/lib/python3.9/site-packages/anndata/_core/anndata.py:1830: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "reading ../data/spatial_transcriptomics/154442/filtered_feature_bc_matrix.h5\n",
      " (0:00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chrav452/miniconda3/envs/spatial2022/lib/python3.9/site-packages/anndata/_core/anndata.py:1830: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n"
     ]
    }
   ],
   "source": [
    "# Read each table and append to our list\n",
    "for i in range(0,len(file_list)):\n",
    "    print(i)\n",
    "    tmp = sc.read_visium('../data/spatial_transcriptomics/'+file_list[i])\n",
    "    tmp.var_names_make_unique()\n",
    "    tmp.obs['sample_id'] = file_list[i]\n",
    "    obj_list.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chrav452/miniconda3/envs/spatial2022/lib/python3.9/site-packages/anndata/_core/anndata.py:1828: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n"
     ]
    }
   ],
   "source": [
    "# Merge all samples into a single AnnData Object \n",
    "adata = an.concat( obj_list , merge='same',uns_merge=\"unique\" )\n",
    "adata.var_names_make_unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can now save the annData object to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('../results/spatial_transcriptomics', exist_ok=True)\n",
    "adata.write_h5ad('../results/spatial_transcriptomics/visium.h5ad' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the dataset saved, we can now safelly remove some of these objects from memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Remove other objects from memory\n",
    "del(obj_list,file_list,adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In Situ Sequencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://export.uppmax.uu.se/snic2022-23-113/courses/spatial_omics_2022/in_situ_sequencing/raw_tiles_with_z.tar.gz\n",
      "Downloading https://export.uppmax.uu.se/snic2022-23-113/courses/spatial_omics_2022/in_situ_sequencing/SpaceTX.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# Define base URL path to the data\n",
    "base_path = \"https://export.uppmax.uu.se/snic2022-23-113/courses/spatial_omics_2022/in_situ_sequencing/\"    \n",
    "\n",
    "# Create directory for the dataset\n",
    "os.makedirs( \"../data/in_situ_sequencing\" , exist_ok= True )\n",
    "\n",
    "# Download necessary tar.gz files\n",
    "for tar_file in [\"raw_tiles_with_z.tar.gz\",\"SpaceTX.tar.gz\"]:\n",
    "    print (\"Downloading \" + base_path + tar_file)\n",
    "    request.urlretrieve( base_path+tar_file , \"../data/in_situ_sequencing/\"+tar_file )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip tar.gz files\n",
    "for tar_file in [\"raw_tiles_with_z.tar.gz\",\"SpaceTX.tar.gz\"]:\n",
    "    tar = tarfile.open(\"../data/in_situ_sequencing/\"+tar_file, \"r:gz\")\n",
    "    \n",
    "    progress = tqdm(tar.getmembers())\n",
    "    for member in progress:\n",
    "        tar.extract(member, path=\"../data/in_situ_sequencing/\")\n",
    "        # set the progress description of the progress bar\n",
    "        progress.set_description(f\"Extracting {member.name}\")\n",
    "    tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check whether the files were downloaded correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "tree --filelimit=100 ../data/in_situ_sequencing/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "07f9dd1b4593d2740b3890f24a384ed77dbeed1429f628e9a8bc1ec24c36d9e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
