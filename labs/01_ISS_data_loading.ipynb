{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 01: ISS data loading\n",
    "\n",
    "## 0) Preparing the raw data\n",
    "\n",
    "To tell the story from the begginning and make this lab as close to practice as possible, we will start with the raw data. Depending on the microscope and imaging software, one would get the data in different formats. In this case, we had a CZI image which was then transofrmed into individual tiles using the [Zeiss ZEN Blue](https://www.zeiss.com/microscopy/int/products/microscope-software/zen-lite.html) free software. \n",
    "\n",
    "This resulted in $(rounds \\times channels \\times tiles \\times Zstack)$ images of $(2048 \\times 2048)$ pixels, where: <br>\n",
    "$rounds = 4$ <br>\n",
    "$channels = 5$; in order, DAPI for the nuclei + 4 primary stains (Cy3, Cy5, Cy7, FITC)   <br>\n",
    "$tiles = 34$ <br>\n",
    "$Zstack = 21$\n",
    "\n",
    "The naming in the experiments is also very variable, so preparing the data by homogeneizing it is usually a good practice. In this case, we will prepare the data to be loaded in the [SpaceTX format](https://spacetx-starfish.readthedocs.io/en/latest/gallery/data_formatting/plot_format_structured_data.html#sphx-glr-gallery-data-formatting-plot-format-structured-data-py). We previously created the helper functions to convert the data into the format. \n",
    "\n",
    "We do not need to load the whole experiment to showcase the different parts of what makes a ISS workflow so only a subset of tiles and rounds will be loaded. Specifically, 9 patches from two rounds are selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from iss_utils import read_starfish\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will create symbolic links to the original files, to avoid changing the file names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '../data/in_situ_sequencing/raw'\n",
    "out_dir = '../data/in_situ_sequencing/SpaceTX_subsample'\n",
    "\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "n_rounds = 2 # selected subset of rounds (0 and 1)\n",
    "n_channels = 5\n",
    "n_zplanes = 21 \n",
    "fov_names = [9,10,11,\n",
    "             16,17,18,\n",
    "             23,24,25] # selected subset of the tiles\n",
    "\n",
    "\n",
    "(primary_dir, nuclei_dir) = read_starfish.format_data(base_dir=base_dir,\n",
    "                                                      out_dir=out_dir,\n",
    "                                                      n_rounds=n_rounds, \n",
    "                                                      n_channels=n_channels,\n",
    "                                                      n_zplanes=n_zplanes,\n",
    "                                                      fov_names=fov_names,\n",
    "                                                      dapi_channel=0, # DAPI channels is the first one\n",
    "                                                      file_format=r'Round{r}/Round{r}_z{z+1:02d}c{ch+1}m{fov:02d}_ORG.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create the coordinate CSV for the images. Notice that here we manually defined the resolution, coordinates, etc. but this can be directly parsed from the experiment metadata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz_res = [0.325, 0.325, 0.5] # micrometers per pixel\n",
    "\n",
    "fov_coordinates = [[3887, 1847, 0], [5530, 1847, 0], [7373, 1847, 0], \n",
    "                   [3887, 3692, 0], [5530, 3692, 0], [7373, 3692, 0], \n",
    "                   [3887, 5535, 0], [5530, 5535, 0], [7373, 5535, 0]] # coordinates in pixels\n",
    "\n",
    "fov_coordinates = np.array(fov_coordinates)*xyz_res # coordintes in micrometers\n",
    "\n",
    "xy_max = 2048*xyz_res[0] # max XY size of a tile in micrometers\n",
    "z_max = xyz_res[2] # max Z size of a tile in micrometers\n",
    "\n",
    "(primary_df, nuclei_df)= read_starfish.create_coordinates(primary_dir=primary_dir,\n",
    "                                                          nuclei_dir=nuclei_dir,\n",
    "                                                          n_rounds=n_rounds,\n",
    "                                                          n_channels=n_channels,\n",
    "                                                          n_zplanes=n_zplanes,\n",
    "                                                          fov_names=fov_names,\n",
    "                                                          xy_max = xy_max,\n",
    "                                                          z_max = z_max,\n",
    "                                                          fov_coordinates=fov_coordinates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we are ready to generate the **SpaceTX** formatted data to load in starfish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_starfish.space_tx(output_dir=out_dir,\n",
    "                       primary_dir=primary_dir,\n",
    "                       nuclei_dir=nuclei_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Reading files with starfish\n",
    "\n",
    "We are in the position of loading in-situ sequencing (ISS) data in Python. A convenient package to do so is [starfish](https://spacetx-starfish.readthedocs.io/en/latest/), but there are multiple ways one may proceed. To install **starfish**, please follow the [instructions](https://spacetx-starfish.readthedocs.io/en/latest/installation/index.html): <br>\n",
    "<code>\n",
    "conda create -n starfish \"python=3.7\" <br>\n",
    "conda activate starfish <br>\n",
    "pip install starfish\n",
    "</code>\n",
    "\n",
    "To see whether it worked, we will load an **Experiment** previously prepared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from starfish import Experiment\n",
    "from starfish.types import Axes\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<starfish.FieldOfView>\n",
      "  Primary Image: <slicedimage.TileSet (z: 21, c: 4, r: 2, x: 2048, y: 2048)>\n",
      "  Auxiliary Images:\n",
      "    nuclei: <slicedimage.TileSet (z: 21, c: 1, r: 2, x: 2048, y: 2048)>, <starfish.FieldOfView>\n",
      "  Primary Image: <slicedimage.TileSet (z: 21, c: 4, r: 2, x: 2048, y: 2048)>\n",
      "  Auxiliary Images:\n",
      "    nuclei: <slicedimage.TileSet (z: 21, c: 1, r: 2, x: 2048, y: 2048)>, <starfish.FieldOfView>\n",
      "  Primary Image: <slicedimage.TileSet (z: 21, c: 4, r: 2, x: 2048, y: 2048)>\n",
      "  Auxiliary Images:\n",
      "    nuclei: <slicedimage.TileSet (z: 21, c: 1, r: 2, x: 2048, y: 2048)>, <starfish.FieldOfView>\n",
      "  Primary Image: <slicedimage.TileSet (z: 21, c: 4, r: 2, x: 2048, y: 2048)>\n",
      "  Auxiliary Images:\n",
      "    nuclei: <slicedimage.TileSet (z: 21, c: 1, r: 2, x: 2048, y: 2048)>, <starfish.FieldOfView>\n",
      "  Primary Image: <slicedimage.TileSet (z: 21, c: 4, r: 2, x: 2048, y: 2048)>\n",
      "  Auxiliary Images:\n",
      "    nuclei: <slicedimage.TileSet (z: 21, c: 1, r: 2, x: 2048, y: 2048)>, <starfish.FieldOfView>\n",
      "  Primary Image: <slicedimage.TileSet (z: 21, c: 4, r: 2, x: 2048, y: 2048)>\n",
      "  Auxiliary Images:\n",
      "    nuclei: <slicedimage.TileSet (z: 21, c: 1, r: 2, x: 2048, y: 2048)>, <starfish.FieldOfView>\n",
      "  Primary Image: <slicedimage.TileSet (z: 21, c: 4, r: 2, x: 2048, y: 2048)>\n",
      "  Auxiliary Images:\n",
      "    nuclei: <slicedimage.TileSet (z: 21, c: 1, r: 2, x: 2048, y: 2048)>, <starfish.FieldOfView>\n",
      "  Primary Image: <slicedimage.TileSet (z: 21, c: 4, r: 2, x: 2048, y: 2048)>\n",
      "  Auxiliary Images:\n",
      "    nuclei: <slicedimage.TileSet (z: 21, c: 1, r: 2, x: 2048, y: 2048)>, <starfish.FieldOfView>\n",
      "  Primary Image: <slicedimage.TileSet (z: 21, c: 4, r: 2, x: 2048, y: 2048)>\n",
      "  Auxiliary Images:\n",
      "    nuclei: <slicedimage.TileSet (z: 21, c: 1, r: 2, x: 2048, y: 2048)>]\n"
     ]
    }
   ],
   "source": [
    "exp = Experiment.from_json(\n",
    "    os.path.join('../data/in_situ_sequencing/SpaceTX_subsample/primary', \"experiment.json\")\n",
    ")\n",
    "print(exp.fovs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we have 9 field of views (FOV), each of them containing 2 rounds of **4 Primary Images** for the different base stains and **1 Auxiliary Image** with the nuclei DAPI stain. \n",
    "\n",
    "Find below an example for how to access the data using the Axes sturcture. In this case we want a cropped version of the only channel, 2nd round, 14th Z-plane of the 25th FOV of the DAPI. <br>\n",
    "**Remember everything is 0-indexed!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = exp['fov_017'].get_image('nuclei').sel({Axes.CH: 0, Axes.ROUND: 0, Axes.ZPLANE: 14, Axes.X: (0, None), Axes.Y: (0, None)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To quickly show the image, we can just use **matplotlib**. Notice how is the actual image accessed from the starfish.ImageStack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img.xarray.values.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) PSF deconvolution\n",
    "\n",
    "It is usually a good idea to perform some kind of deconvolution along the Z axis of the volume in order to remove the point spread function (PSF) generated by the microscope while acquiring the images. Thus, the PSF depends on the optical parameters of the microscope. In order to model it we will use the [PSFModels](https://github.com/tlambert03/PSFmodels) package.\n",
    "\n",
    "To install it in the conda environment: <br>\n",
    "<code> pip install psfmodels</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psfmodels as psfm\n",
    "from skimage import restoration\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a very computationally demanding step, that usually requires GPU support. That is why we will perform the operation on only a cropped part of one channel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = exp['fov_017'].get_image('primary').sel({Axes.CH: 3, Axes.ROUND: 1, Axes.ZPLANE: (0, None), Axes.X: (1200, 1712), Axes.Y: (1400, 1912)})\n",
    "print(img.xarray.values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_img = img.xarray.values.squeeze()\n",
    "plt.imshow(np.log(2**16*np.max(np_img,axis=0)+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "First we will create a the PSF based on the metadata extracted from the experiment. Finding all the data can be a little challenging depending on the format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz_res = [0.325, 0.325, 0.5] # micrometers per pixel\n",
    "\n",
    "psf = psfm.make_psf(\n",
    "    z=21,   # number of Z planes to calculate\n",
    "    dxy=xyz_res[0], # pixel size in microns\n",
    "    dz=xyz_res[2],     # axial size in microns\n",
    "    nx=31,  # XY size of the output PSF\n",
    "    pz=0,   # point source position above the coverslip\n",
    "    ti0=610,    # working distance of the objective in microns\n",
    "    ni0=1.0,    # design value of the immersion medium refractive index\n",
    "    ni=1.0,     # experimental value of the immersion medium refractive index\n",
    "    tg0=170.0,  # design value of the coverslip thickness in microns\n",
    "    tg=170,     # experimental value of the coverslip thickness in microns\n",
    "    ng0=1.0,    # design value of the coverslip refractive index\n",
    "    ng=1.0,     # experimental value of the coverslip refractive index\n",
    "    ns=1.0,     # sample refractive index\n",
    "    wvl=.519,  # emission wavelength in microns\n",
    "    NA=0.8,     # numercal aperture of the objective lense\n",
    "    model='vectorial'  # PSF model to use\n",
    "                    )\n",
    "\n",
    "# psf.dtype\n",
    "# psf[psf<1e-3*np.max(psf)] = 0\n",
    "# # psf=psf/np.sum(psf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we apply the Richardson Lucy deconvolution included **skimage**. There are several ways of optimizing this in order to allow for GPU support and speed up the process.But for this example, this function is simple enough.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "ss = 5\n",
    "deconvolved_stack = np_img - gaussian_filter(np_img, sigma=(ss,ss,ss))\n",
    "deconvolved_stack[deconvolved_stack<0]=0\n",
    "\n",
    "deconvolved_RL = restoration.richardson_lucy(deconvolved_stack, \n",
    "                                            psf, iterations=10,\n",
    "                                            clip=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the deconvolution is performed, we can compare the maximum intensity projected (MIP) images for two spots before and after. Hopefully, one can see how the PSF was removed and the dots look much crisper in after the deconvolution, allowing better detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(2**16*np.max(np_img,axis=0)[256:,256:])\n",
    "plt.title('Before deconvolution')\n",
    "plt.axis('off')\n",
    "plt.colorbar()\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(2**16*np.max(deconvolved_RL,axis=0)[256:,256:])\n",
    "plt.title('After deconvolution (no scaling)')\n",
    "plt.axis('off')\n",
    "plt.colorbar()\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(2**16*np.max(deconvolved_RL,axis=0)[256:,256:], vmax=9000, vmin=500)\n",
    "plt.title('After deconvolution (scaled)')\n",
    "plt.axis('off')\n",
    "plt.colorbar()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Register and stitch\n",
    "It is usually the case that the rounds are slightly displaced. This hinders the decoding process, as the detecteds spots might not be aligned creating false positives or negatives. To solve this, some kind of registration is needed between rounds. Additionally, the FOV need to be stitched together, accounting for the overlap, to create the full image. \n",
    "\n",
    "It is a good idea to do both together to optimize the process. Depending on the complexity and the desired results, there are several tools for doing this. [Ashlar](https://github.com/labsyspharm/ashlar) is a widely used tool for this purpose. [Starfish](https://spacetx-starfish.readthedocs.io/en/latest/gallery/tutorials/plot_image_registration.html#sphx-glr-gallery-tutorials-plot-image-registration-py) also offers registration tools. <br>\n",
    "Again registering and stitching the whole image is very computationally demanding, so we will show a manual registration process. \n",
    "\n",
    "Fisrt, we will use the starfish **diagnose_registration** tool to evaluate how bad is the displacement between rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from starfish.util.plot import diagnose_registration\n",
    "from starfish.core.image._registration.transforms_list import TransformsList\n",
    "from skimage import transform\n",
    "from starfish.core.types import Axes, TransformType\n",
    "from starfish.image import ApplyTransform\n",
    "\n",
    "matplotlib.rcParams[\"figure.dpi\"] = 150\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = exp['fov_017'].get_image('nuclei').reduce({Axes.ZPLANE}, 'max')\n",
    "diagnose_registration(img, {Axes.ROUND:0}, {Axes.ROUND:1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is obvious that the fact that the images are not aligned would greatly affect the decoding. Thus, it is necessary to find the translation that would make the channels align."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_list = TransformsList([\n",
    "    ({Axes.ROUND: 0}, TransformType.SIMILARITY, transform.SimilarityTransform(translation=(650,-35))),\n",
    "    ({Axes.ROUND: 1}, TransformType.SIMILARITY, transform.SimilarityTransform())\n",
    "                                ])\n",
    "transforms_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warp = ApplyTransform.Warp()\n",
    "registered_imgs = warp.run(img, transforms_list=transforms_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnose_registration(registered_imgs, {Axes.ROUND:0}, {Axes.ROUND:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
