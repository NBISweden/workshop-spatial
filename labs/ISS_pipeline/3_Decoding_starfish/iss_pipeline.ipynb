{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# ISS Processing Workflow\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\n\nimport starfish\nfrom starfish.image import ApplyTransform, Filter, LearnTransform, Segment\nfrom starfish.spots import FindSpots, DecodeSpots, AssignTargets\nfrom starfish.types import Axes, FunctionSource\n\ntest = os.getenv(\"TESTING\") is not None\n\n\ndef iss_pipeline(fov, codebook):\n    primary_image = fov.get_image(starfish.FieldOfView.PRIMARY_IMAGES)\n\n    # register the raw image\n    learn_translation = LearnTransform.Translation(reference_stack=fov.get_image('dots'),\n                                                   axes=Axes.ROUND, upsampling=100)\n    transforms_list = learn_translation.run(\n        primary_image.reduce({Axes.CH, Axes.ZPLANE}, func=\"max\"))\n    warp = ApplyTransform.Warp()\n    registered = warp.run(primary_image, transforms_list=transforms_list,  in_place=False, verbose=True)\n\n    # filter raw data\n    masking_radius = 15\n    filt = Filter.WhiteTophat(masking_radius, is_volume=False)\n    filtered = filt.run(registered, verbose=True, in_place=False)\n\n    bd = FindSpots.BlobDetector(\n        min_sigma=1,\n        max_sigma=10,\n        num_sigma=30,\n        threshold=0.01,\n        measurement_type='mean',\n    )\n\n    # detect spots using laplacian of gaussians approach\n    dots_max = fov.get_image('dots').reduce((Axes.ROUND, Axes.ZPLANE), func=\"max\")\n    # locate spots in a reference image\n    spots = bd.run(reference_image=dots_max, image_stack=filtered)\n\n    # decode the pixel traces using the codebook\n    decoder = DecodeSpots.PerRoundMaxChannel(codebook=codebook)\n    decoded = decoder.run(spots=spots)\n\n    # segment cells\n    seg = Segment.Watershed(\n        nuclei_threshold=.16,\n        input_threshold=.22,\n        min_distance=57,\n    )\n    label_image = seg.run(primary_image, fov.get_image('dots'))\n\n    # assign spots to cells\n    ta = AssignTargets.Label()\n    assigned = ta.run(label_image, decoded)\n\n    return assigned, label_image\n\n\n# process all the fields of view, not just one\ndef process_experiment(experiment: starfish.Experiment):\n    decoded_intensities = {}\n    regions = {}\n    for i, (name_, fov) in enumerate(experiment.items()):\n        decoded, segmentation_results = iss_pipeline(fov, experiment.codebook)\n        decoded_intensities[name_] = decoded\n        regions[name_] = segmentation_results\n        if test and i == 1:\n            # only run through 2 fovs for the test\n            break\n    return decoded_intensities, regions\n\n\n# run the script\nif test:\n    exp = starfish.Experiment.from_json(\n        \"https://d2nhj9g34unfro.cloudfront.net/browse/formatted/20180926/iss_breast/experiment.json\")\nelse:\n    exp = starfish.Experiment.from_json(\"iss/formatted/experiment.json\")\ndecoded_intensities, regions = process_experiment(exp)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}